# WebMind - Chatbot Intelligent avec Acc√®s Web

<div align="center">

[![Python](https://img.shields.io/badge/Python-3.9%2B-blue?style=for-the-badge&logo=python)](https://python.org)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.28%2B-red?style=for-the-badge&logo=streamlit)](https://streamlit.io)
[![Ollama](https://img.shields.io/badge/Ollama-Latest-green?style=for-the-badge)](https://ollama.com)


---

![WebMind Demo](Capture_d'√©cran.png)

</div>

---

## Table des Mati√®res

- [Aper√ßu](#aper√ßu)
- [Fonctionnalit√©s](#fonctionnalit√©s)
- [Architecture](#architecture)
- [Installation](#installation)
- [D√©ploiement](#d√©ploiement)
- [Utilisation](#utilisation)
- [Configuration](#configuration)
- [Performance](#performance)
- [Contribution](#contribution)

---

## Aper√ßu

**WebMind** est une application de chatbot de nouvelle g√©n√©ration qui r√©volutionne l'interaction avec l'intelligence artificielle en combinant :

- **Intelligence Locale** : Utilise des mod√®les de langage open-source via Ollama
- **Acc√®s Web Temps R√©el** : Recherche automatique d'informations actualis√©es
- **Confidentialit√© Totale** : Toutes les op√©rations sont effectu√©es localement
- **Streaming Avanc√©** : R√©ponses affich√©es en temps r√©el

### Cas d'Usage

- **Actualit√©s et √âv√©nements** : Obtenez des informations √† jour sur l'actualit√© mondiale
- **Recherche Acad√©mique** : Acc√©dez √† des donn√©es r√©centes pour vos recherches
- **Veille Technologique** : Restez inform√© des derni√®res innovations
- **Support D√©cisionnel** : Analyses bas√©es sur des donn√©es actuelles

---

## Fonctionnalit√©s

### Fonctionnalit√©s Principales

| Fonctionnalit√©                           | Description                                    | Avantage                       |
| ---------------------------------------- | ---------------------------------------------- | ------------------------------ |
| **Interface Chat Moderne**               | Interface utilisateur intuitive avec Streamlit | Exp√©rience utilisateur fluide  |
| **RAG (Retrieval-Augmented Generation)** | Recherche web + g√©n√©ration IA                  | R√©ponses pr√©cises et actuelles |
| **Streaming en Temps R√©el**              | Affichage progressif des r√©ponses              | Interaction naturelle          |
| **Multi-Mod√®les**                        | Support de tous les mod√®les Ollama             | Flexibilit√© maximale           |
| **Historique de Conversation**           | M√©moire contextuelle des √©changes              | Conversations coh√©rentes       |

### S√©curit√© et Confidentialit√©

- **Traitement Local** : Aucune donn√©e envoy√©e vers des serveurs externes
- **Open Source** : Code transparent et v√©rifiable
- **Contr√¥le Total** : Vous ma√Ætrisez vos donn√©es
- **Conformit√© RGPD** : Respect de la vie priv√©e

---

## Architecture

### Stack Technologique

```mermaid
graph TD
    A[Utilisateur] --> B[Streamlit UI]
    B --> C[WebMind Core]
    C --> D[DuckDuckGo Search]
    C --> E[Ollama API]
    E --> F[Mod√®le LLM Local]
    D --> G[Web Results]
    G --> C
    F --> C
    C --> B
    B --> A
```

### Composants

- **Frontend** : [Streamlit](https://streamlit.io/) - Interface web r√©active
- **Backend IA** : [Ollama](https://ollama.com/) - Gestion des mod√®les locaux
- **Moteur de Recherche** : [DuckDuckGo Search](https://pypi.org/project/duckduckgo-search/) - Recherche web priv√©e
- **Langage** : Python 3.9+ - Performance et simplicit√©

---

## Installation

### Pr√©requis Syst√®me

- **Syst√®me d'Exploitation** : Windows 10/11, macOS 10.15+, Ubuntu 18.04+
- **Python** : Version 3.9 ou sup√©rieure
- **M√©moire RAM** : 8 GB minimum (16 GB recommand√©)
- **Espace Disque** : 10 GB libres (pour les mod√®les)

### Installation d'Ollama

T√©l√©chargez et installez Ollama depuis le [site officiel](https://ollama.com/).

```bash
# V√©rifiez l'installation
ollama --version

# T√©l√©chargez un mod√®le (exemple avec Gemma)
ollama pull gemma2
```

### Installation du Projet

```bash
# Clonez le projet
git clone https://github.com/yassinekamouss/WebMind.git
cd webmind

# Cr√©ez un environnement virtuel
python -m venv venv

# Activez l'environnement virtuel
# Windows:
venv\Scripts\activate
# macOS/Linux:
source venv/bin/activate

# Installez les d√©pendances
pip install -r requirements.txt
```

### Lancement de l'Application

```bash
# D√©marrez Ollama (si pas d√©j√† fait)
ollama serve

# Lancez WebMind
streamlit run main.py
```

L'application sera disponible √† l'adresse : `http://localhost:8501`

---

## D√©ploiement

### Application en Ligne

**WebMind** est d√©ploy√© et accessible en ligne via Streamlit Cloud :

üåê **[Acc√©der √† WebMind](https://webmind.streamlit.app/)**

L'application h√©berg√©e offre les m√™mes fonctionnalit√©s que l'installation locale, avec l'avantage d'√™tre directement accessible depuis votre navigateur sans installation pr√©alable.

> **Note** : L'application en ligne utilise les ressources partag√©es de Streamlit Cloud. Pour des performances optimales et une confidentialit√© maximale, nous recommandons l'installation locale.

---

## Utilisation

### Interface Utilisateur

1. **Zone de Chat** : Saisissez vos questions dans la barre de chat
2. **Recherche Automatique** : L'IA recherche automatiquement des informations pertinentes
3. **R√©ponse Contextualis√©e** : Obtenez une r√©ponse bas√©e sur les donn√©es web r√©centes
4. **Historique** : Consultez l'historique de vos conversations

### Exemples de Questions

```
"Quelles sont les derni√®res nouvelles sur le changement climatique ?"
"Quelles sont les tendances technologiques de 2025 ?"
"Comment √©voluent les march√©s financiers aujourd'hui ?"
"Quelles sont les derni√®res d√©couvertes en intelligence artificielle ?"
```

---

## Configuration

### Changement de Mod√®le

Modifiez la constante `OLLAMA_MODEL` dans `main.py` :

```python
# Mod√®les recommand√©s
OLLAMA_MODEL = 'llama3'      # Polyvalent et rapide
OLLAMA_MODEL = 'gemma2'      # Excellent pour le fran√ßais
OLLAMA_MODEL = 'mistral'     # Optimis√© pour le code
OLLAMA_MODEL = 'phi3'        # L√©ger et efficace
```

### Personnalisation de la Recherche

Ajustez les param√®tres de recherche dans la fonction `search_the_web()` :

```python
# Nombre de r√©sultats (1-10)
results = list(ddgs.text(query, max_results=4))

# R√©gion de recherche (facultatif)
results = list(ddgs.text(query, region='fr-fr'))
```

### Variables d'Environnement

Cr√©ez un fichier `.env` pour personnaliser l'application :

```env
OLLAMA_MODEL=gemma2
MAX_SEARCH_RESULTS=4
APP_TITLE=WebMind - Mon Assistant IA
```

---

## Performance

### Benchmarks

| Mod√®le  | Taille | RAM Requise | Vitesse | Qualit√© |
| ------- | ------ | ----------- | ------- | ------- |
| Phi3    | 2.2GB  | 4GB         | √âlev√©e  | Moyenne |
| Gemma2  | 5.5GB  | 8GB         | Bonne   | Bonne   |
| Llama3  | 8.0GB  | 12GB        | Moyenne | √âlev√©e  |
| Mistral | 7.2GB  | 10GB        | Bonne   | Bonne   |

### Optimisations

- **GPU** : Utilisez CUDA/ROCm pour des performances 10x sup√©rieures
- **Quantification** : Mod√®les Q4 pour r√©duire l'usage m√©moire
- **Cache** : Mise en cache automatique des r√©sultats de recherche

---

## Contribution

Nous accueillons toutes les contributions ! Voici comment participer :

### Signaler un Bug

1. V√©rifiez que le bug n'a pas d√©j√† √©t√© signal√©
2. Cr√©ez une issue d√©taill√©e avec :
   - Description du probl√®me
   - √âtapes de reproduction
   - Environnement (OS, Python, versions)
   - Logs d'erreur

### Proposer une Fonctionnalit√©

1. Cr√©ez une issue avec le label "enhancement"
2. D√©crivez clairement la fonctionnalit√© souhait√©e
3. Expliquez l'int√©r√™t et les cas d'usage

### Contribuer au Code

1. Fork le projet
2. Cr√©ez une branche feature (`git checkout -b feature/nouvelle-fonctionnalite`)
3. Committez vos changements (`git commit -m 'Ajout nouvelle fonctionnalit√©'`)
4. Pushez la branche (`git push origin feature/nouvelle-fonctionnalite`)
5. Ouvrez une Pull Request

---

<div align="center">

**WebMind - R√©alis√© avec ‚ù§Ô∏è par YASSINE KAMOUSSI**

</div>

---
